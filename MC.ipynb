{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6><h1 align = center>Monte Carlo Fun </h1 ></font>      \n",
    "\n",
    "<font size = 4><h2 align = center> Derek Sikorski </font><h2>\n",
    "\n",
    "---\n",
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><h1 align = center>File Summary</h1 ></font>      \n",
    "\n",
    "**Purpose:** \n",
    "This file is meant to handle MCing data used for the Hyperion SMF project. The data broadly includes:\n",
    "1. COSMOS2020 photometry\n",
    "2. Assorted ground-based spectroscopy\n",
    "3. HST grism data\n",
    "\n",
    "**Outputs:**\n",
    "This code produces two separate catalogs of MCed redshifts. One is for the COSMOS photometry while the other is for any other is for any other assortment of observations. The logic is that the photoz's are drawn completely randomly for all galaxies in the sample whereas the galaxies with other observations maybe be chosen by a variety of functions. Therefore, it is easiest to simply replace the redshifts of the galaxies with extra observations in place.\n",
    "\n",
    "**General Logic**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skewnorm\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><h1 align = center>MC Functions</h1 ></font>    \n",
    "\n",
    "---> Define the MC function and my PDF (a skew-normal in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCz(niter, zs, weights, z_range, MC_fn, plot_field=\"\", plot_zrange=\"\", verbose=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Performs a Monte Carlo on the redshift distribution of input galaxies\n",
    "\n",
    "    INPUTS:\n",
    "        - niter (int)   = Number of MC iterations to run\n",
    "        - zs (array)    = List of median redshift values\n",
    "        - weights (array)   = List of the MC weights for each object. A new z is drawn from the PDF if random_number >= weight\n",
    "        - z_range (array)   = Range of redshifts to keep\n",
    "        - MC_fun (fn)   = Python function used to generate the new redshift values for the galaxies\n",
    "        - plot_field (str)    = Path to the directory where plots should be saved. If left as \"\", then no plots are saved\n",
    "        - plot_zrange (str)    = Path to the directory where plots of galaxies in z_range should be saved.\n",
    "        - verbose (bool)    = If you want to print the status bar via tqdm.notebook\n",
    "        - **kwargs = For the MC_fun\n",
    "        \n",
    "    OUTPUTS:\n",
    "        - (array) --> Indices in redshift array of objects falling in z_range at least once\n",
    "        - (array) --> 2D array of redshifts of shape (len(zs), niter)\n",
    "        - (array) --> 2D array of of indices which failed the MC draw (i.e. new z was drawn)\n",
    "    \"\"\"\n",
    "    ## Setup for MC\n",
    "    new_zs = [] # Fill with new redshifts\n",
    "    iterable = tqdm(range(niter)) if verbose else range(niter)      # What to iterate over in for-loop based on 'verbose' option\n",
    "    drawn_idxs = [] # Fill with idxs that were drawn\n",
    "\n",
    "    ## Run the MC iterations\n",
    "    for n in iterable:\n",
    "        z_in = np.copy(zs)      # Copy of redshifts to manipulate\n",
    "\n",
    "        ## Pick galaxies to get new z's and change where need\n",
    "        new_idxs = np.where( np.random.random(size=len(zs)) >= weights )    # Which z's to change\n",
    "        nz = MC_fn(*kwargs.values())            # Pick new z's\n",
    "        z_in[new_idxs] = nz[new_idxs]    # Replace redshifts where needed\n",
    "\n",
    "        new_zs.append(z_in)      # Add to list of redshifts   \n",
    "        drawn_idxs.append(new_idxs)\n",
    "\n",
    "    new_zs = np.array(new_zs)   # MCed redshifts\n",
    "\n",
    "    ## Find which galaxies fell in z-range at least once ###\n",
    "    z_bool = ((z_range[0]< new_zs) & (new_zs < z_range[1])).any(axis=0)\n",
    "    good_idxs = np.where(z_bool)[0]     # Where the condition is met\n",
    "\n",
    "    return good_idxs, new_zs.transpose(), drawn_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_PDF(alpha, omega, loc):\n",
    "    \"\"\"\n",
    "    PDFs to draw the new redshifts from. Skewed-normal based on the confidence interval from COSMOS2020\n",
    "\n",
    "    INPUTS:\n",
    "        - alpha (array)    = shape parameters\n",
    "        - omega (array)   = scale parameters\n",
    "        - loc (array)   = location parameters\n",
    "    OUTPUTS:\n",
    "        - (array)   = New redshift values.\n",
    "    \"\"\"\n",
    "    z_vals = skewnorm.rvs(a=alpha, loc=loc, scale=omega) # Find new zs based on skew-normal\n",
    "    return z_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><h1 align = center>Fit Skew-Normal Distributions</h1 ></font>      \n",
    "\n",
    "---> The first step is to fit skew-normal distributions to each of the COSMOS2020 objects that I want. So, I need to first define the functions for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFn(params, z_params):\n",
    "    \"\"\"Calculate the residual based on the area between the 16th/84th percentile, and difference between median\"\"\"\n",
    "    # Unpack the parameters\n",
    "    alpha, omega, loc = params\n",
    "    \n",
    "    # Create the skew-normal distribution\n",
    "    dist = skewnorm(alpha, scale=omega, loc=loc)\n",
    "\n",
    "    # Calculate the CDF at points 16th, 50th, and 84th percentiles\n",
    "    cdf_16, cdf_50, cdf_84 = dist.cdf(z_params[1]),  dist.cdf(z_params[0]), dist.cdf(z_params[2])\n",
    "    \n",
    "    # The areas we want to match\n",
    "    area_left = cdf_50 - cdf_16\n",
    "    area_right = cdf_84 - cdf_50\n",
    "    \n",
    "    # Objective is to make both areas equal to 0.34\n",
    "    return (area_left - 0.34)**2 + (area_right - 0.34)**2 + (dist.median()-z_params[0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitDist(zmed, l68, u68, plot_path = \"\", cid = None):\n",
    "    \"\"\"Fit for skew-normal parameters based on the 3-point redshift statistics\"\"\"\n",
    "\n",
    "    wi = 2/3*(u68 - l68)    # Initial omega\n",
    "    var = ((zmed-l68)**2 + (u68-zmed)**2)/2     # variance estimate\n",
    "\n",
    "    # Estimate location and shape based on which area which std dev is smaller\n",
    "    if (zmed - l68) < (u68-zmed): li, ai = l68 -wi/4, 50*var**0.5       # upper error is larger\n",
    "    else:   li, ai =  u68 + wi/4, -50*var**0.5          # lower error is larger\n",
    "\n",
    "    # Minimize the objective function\n",
    "    result = minimize(costFn, [ai, wi, li], tol=1e-14, options={'maxiter':100},\n",
    "                    args=([zmed, l68, u68]), bounds = ((-12, 12), (0,5), (0,7)))\n",
    "    \n",
    "    af, wf, lf = result.x   # Optimized parameters\n",
    "    residual = costFn(result.x, [zmed, l68, u68])\n",
    "\n",
    "    if plot_path != \"\": fit_Plot(af, wf, lf, zmed, l68, u68, plot_path, cid)\n",
    "\n",
    "    return af, wf, lf, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_Plot(af, wf, lf, zmed, l68, u68, plot_path, cid):\n",
    "    \"\"\"Plot for the fitting function above\"\"\"\n",
    "    dist = skewnorm(af, scale=wf, loc=lf)\n",
    "    rvs = dist.rvs(10000)\n",
    "\n",
    "    delta =af / np.sqrt(1 +af**2)\n",
    "    gamma = (4-np.pi)/2 * (delta*np.sqrt(np.pi/2))**3 / (1-2*delta**2/np.pi)**1.5\n",
    "    mu = dist.mean()\n",
    "    final_med = dist.median()\n",
    "\n",
    "    # Final skew-normal distribution\n",
    "    p_l68 = dist.cdf(zmed) - dist.cdf(l68)\n",
    "    p_u68 = dist.cdf(u68) - dist.cdf(zmed)\n",
    "    xs = np.linspace(zmed-3*(zmed-l68), zmed+3*(u68-zmed), 1000)\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.title(rf\"C20 ID = {int(cid)}    $\\alpha$={round(af, 2)}       $\\omega$={round(wf, 2)}      $\\xi$={round(lf, 2)}    $\\gamma$={round(gamma, 2)}\")\n",
    "    plt.hist(rvs, density=True, bins=100, label=f\"N = {10000} draws\", alpha=0.75)\n",
    "    plt.plot(xs, dist.pdf(xs))\n",
    "    plt.vlines(mu, ymin=0, ymax=2, color='red', label=f\"Mean = {round(mu, 3)}\")\n",
    "    plt.vlines(final_med, ymin=0, ymax=2, color='orange', label=f\"Median = {round(final_med, 3)}    ({zmed})\")\n",
    "    plt.vlines(l68, ymin=0, ymax=1, color='g', label=f\"Lower-bound  ({round(p_l68,3)})\")\n",
    "    plt.vlines(u68, ymin=0, ymax=1, color='m', label=f\"Upper-bound  ({round(p_u68, 3)})\")\n",
    "    plt.legend()\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we're ready to actually fit this to the COSMOS data. First, we need to trim the data down to only those galaxies we're interested in.\n",
    "\n",
    "We start by trimming galaxies that are missing one of the 3 three-point stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of galaxies = 1720700\n",
      "Number of bad galaxies = 19258\n"
     ]
    }
   ],
   "source": [
    "## READ IN COSMOS DATA ##\n",
    "\n",
    "cosmos_file = fits.open(r\"C:/Users/sikor/OneDrive/Desktop/BigData/COSMOS2020/COSMOS2020_CLASSIC_R1_v2.0.fits\")\n",
    "c20p = cosmos_file[1].data\n",
    "\n",
    "## FIND BAD GALAXIES ##\n",
    "bad_ids = np.where((np.isnan(c20p[\"lp_zPDF\"]) == True) |        # No redshift from lephare\n",
    "                   (np.isnan(c20p[\"lp_zPDF_l68\"]) == True) |    # No lower-68-percentile from lephare\n",
    "                   (np.isnan(c20p[\"lp_zPDF_u68\"]) == True))[0]  # no upper-68-percentile from lephare\n",
    "\n",
    "c20p_cut = np.delete(c20p, bad_ids)\n",
    "\n",
    "print(f\"Number of galaxies = {len(c20p)}\")\n",
    "print(f\"Number of bad galaxies = {len(bad_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's cut based on RA, Dec, LP-type, and IRAC Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of galaxies = 287363\n",
      "Number of bad galaxies = 1414079\n"
     ]
    }
   ],
   "source": [
    "## CUT DATA TO POTENTIALLY USABLE ##\n",
    "ra_range = (149.6, 150.52)  \n",
    "dec_range = (1.74, 2.73)\n",
    "IRAC_cut = 25.4\n",
    "\n",
    "\n",
    "g_idxs = np.where((c20p_cut[\"ALPHA_J2000\"] >= ra_range[0]) & (c20p_cut[\"ALPHA_J2000\"] <= ra_range[1])       # RA\n",
    "                & (c20p_cut[\"DELTA_J2000\"] >= dec_range[0]) & (c20p_cut[\"DELTA_J2000\"] <= dec_range[1])     # DEC\n",
    "                & ((c20p_cut[\"IRAC_CH1_MAG\"] <= IRAC_cut) | (c20p_cut[\"IRAC_CH2_MAG\"] <= IRAC_cut)) # IRAC\n",
    "                & ((c20p_cut[\"lp_type\"] == 0) | (c20p_cut[\"lp_type\"] == 2)))        # LePhare type\n",
    "\n",
    "g_c20p = c20p_cut[g_idxs]\n",
    "\n",
    "print(f\"Number of galaxies = {len(g_c20p)}\")\n",
    "print(f\"Number of bad galaxies = {len(c20p_cut) - len(g_c20p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we make one more cut based on how close the 16th and 84th percentile of the redshift PDF is to our redshift range of interest. In our case, we care about $2\\leq z \\leq 3$, so we cut based on that.\n",
    "\n",
    "Specifically, we want to include galaxies which are 3 times $\\sigma_-$ above $z=3$, or 3 times $\\sigma_+$ below $z=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining galaxies =  99999\n"
     ]
    }
   ],
   "source": [
    "## CUT BASED ON REDSHIFT PROXIMATEY ##\n",
    "z_min, z_max = 2, 3     # Redshift range\n",
    "n_sig = 3           # Number of sigma acceptable\n",
    "\n",
    "med, l68, u68 = g_c20p[\"lp_zPDF\"], g_c20p[\"lp_zPDF_l68\"], g_c20p[\"lp_zPDF_u68\"]\n",
    "sig_l, sig_u = med - l68, u68 - med\n",
    "\n",
    "in_zrange = np.where(( (med<=z_max) & (u68+n_sig*sig_u >=z_min) ) | ( (med>=z_min) & (l68-n_sig*sig_l <= z_max) )  )\n",
    "\n",
    "small_c20p = g_c20p[in_zrange]\n",
    "\n",
    "print(\"Number of remaining galaxies = \", len(small_c20p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. We have our sample of galaxies. Let's go ahead and do our fits now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54670d52f8b44583871954fd816775f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99999 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "# save_fits = np.zeros((small_c20p.shape[0], 5))\n",
    "save_fits = np.load('zFits/zFits.npy')\n",
    "\n",
    "for idx in tqdm(range(small_c20p.shape[0])):\n",
    "\n",
    "    c_index = small_c20p[\"ID\"][idx]\n",
    "\n",
    "    if np.any(save_fits[:,0] == c_index):\n",
    "        continue\n",
    "    else:\n",
    "        zm, l68, u68 = small_c20p[\"lp_zPDF\"][idx], small_c20p[\"lp_zPDF_l68\"][idx], small_c20p[\"lp_zPDF_u68\"][idx]\n",
    "        a, w, l, r = fitDist(zm, l68, u68)\n",
    "\n",
    "        save_fits = np.append(save_fits, np.array([[c_index, a, w, l, r]]), axis=0)\n",
    "\n",
    "# np.save(f\"zFits/zFits.npy\", save_fits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><h1 align = center>Generate Only photoz catalogs</h1 ></font>      \n",
    "\n",
    "---> I want to make MC catalogs for just the COSMOS catalog. So, for each iteration, I simply draw from the p(z) for that photometric object in the COSMOS catalog. Later on, I can replace these when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I need to find the C20 Galaxies with good skew-normal fits. This is based on how far the median of the skew-normal is from the median redshift reported by LePhare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of good fits =  70049\n",
      "Number of bad fits =  234\n"
     ]
    }
   ],
   "source": [
    "### FIND GOOD FITS ###\n",
    "all_fits = np.load(\"zFits/zFits.npy\")\n",
    "max_sep = 0.1   # Max allowable redshift separation\n",
    "\n",
    "# Pack up the separations\n",
    "med_diffs = []\n",
    "for f in tqdm(all_fits):\n",
    "    skn = skewnorm(f[1], scale=f[2], loc=f[3])\n",
    "    z_med = c20p[\"lp_zPDF\"][int(f[0])-1]\n",
    "    med_diffs.append(skn.median() - z_med) \n",
    "\n",
    "# Find bad separations and delete\n",
    "b_fits = np.where(np.abs(med_diffs) > max_sep)[0]    \n",
    "g_fits = np.delete(all_fits, b_fits, axis=0)\n",
    "\n",
    "print(\"Number of good fits = \", len(g_fits))\n",
    "print(\"Number of bad fits = \", len(b_fits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now MC the photometric sources by just drawing random values from the skew-normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c0d317b30643448ed9b2b2ddea2a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### RUN THE MC ####\n",
    "# ========================================================\n",
    "# ========================================================\n",
    "for run in range(1):\n",
    "    niter = 100      # Number of iterations\n",
    "\n",
    "    z_range = [2,3]         # Redshift range for \n",
    "\n",
    "    phot_med = c20p[\"lp_zPDF\"][g_fits[:,0].astype(int)-1]\n",
    "\n",
    "    # ========================================================\n",
    "    # ========================================================\n",
    "    # ========================================================\n",
    "\n",
    "    ## MC ##\n",
    "    phot_ids, new_pzs = MCz(niter ,phot_med, np.zeros(len(g_fits)), z_range, my_PDF,\n",
    "                         verbose=True, alpha=g_fits[:,1], omega=g_fits[:,2], loc=g_fits[:,3])\n",
    "\n",
    "    ## Update bad galaxies ##\n",
    "\n",
    "    ## WRITE TO RESULT FILE ##\n",
    "\n",
    "    # Update dtypes\n",
    "    dtypes = [c20p.dtype.descr[0]] + [(f\"MC_iter{n}\", \">f8\") for n in range(niter)]\n",
    "\n",
    "    # Make array to fill\n",
    "    write_arr = np.zeros(shape=(len(g_fits)), dtype=dtypes)\n",
    "\n",
    "    write_arr[\"ID\"] = c20p[\"ID\"][g_fits[:,0].astype(int)-1]\n",
    "    for n in range(niter):\n",
    "        write_arr[f\"MC_iter{n}\"] = new_pzs[:,n]\n",
    "\n",
    "    np.save(rf\"C:/Users/sikor/OneDrive/Desktop/BigData/COSMOS2020/C20_MC_100_{run}.npy\", write_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet, we now have our MC iterations for the photometric sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6><h1 align = center>Spectroscopy</h1 ></font>      \n",
    "\n",
    "---> Now, I'll run MCs for the spectra (ground-based and grism). However, some objects are repeated in both spec-catalogs, so I need to first pull out those objects as they are handled differently. For now, I'll just load in the data...\n",
    "\n",
    "For each object, I still need to know if the object has a well-defined p(z) to draw from in the COSMOS2020 catalog, or if it is in the catalog in the first place. If it's not a COSMOS object, I can't use it because it has no photometry (thus no physical properties). If it's missing the p(z), it's not useful for the MC process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Photoz's to check p(z) for spectra\n",
    "cosmos_file = fits.open(r\"C:/Users/sikor/OneDrive/Desktop/BigData/COSMOS2020/COSMOS2020_CLASSIC_R1_v2.0.fits\")\n",
    "c20p = cosmos_file[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of C20 spectra: 42776\n",
      "Number of Grism redshifts: 12764\n"
     ]
    }
   ],
   "source": [
    "### LOAD SPECTRA ###\n",
    "\n",
    "# GROUND-BASED (GB)\n",
    "specz_cat = np.loadtxt(\"./Data/master_specz_COSMOS_BF_v4b.cat\", dtype=object)   # Load in the data\n",
    "# Fix up the formatting for the spec data-file:\n",
    "new_array = []\n",
    "for idx in range(specz_cat.shape[1]):\n",
    "    try:\n",
    "        col = specz_cat[:,idx].astype(np.float32)\n",
    "    except:\n",
    "        col = specz_cat[:,idx]\n",
    "    new_array.append(col)\n",
    "\n",
    "c20s = np.array(new_array, dtype=object)\n",
    "c20s = np.transpose(c20s)\n",
    "\n",
    "print(f\"Number of C20 spectra: {c20s.shape[0]}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# GRISM\n",
    "# Need blended flags from griz_cat\n",
    "griz_cat = np.loadtxt(\"./Data/HST_Hyp_zcat.v1.2.cat\",  usecols=range(16), dtype=object)   # Load in the data\n",
    "new_array = []\n",
    "for idx in range(griz_cat.shape[1]):\n",
    "    try:\n",
    "        col = griz_cat[:,idx].astype(np.float32)\n",
    "    except:\n",
    "        col = griz_cat[:,idx]\n",
    "    new_array.append(col)\n",
    "\n",
    "griz = np.array(new_array, dtype=object)\n",
    "griz = np.transpose(griz)\n",
    "\n",
    "print(f\"Number of Grism redshifts: {griz.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check:\n",
    "- Are the objects in COSMOS\n",
    "- Do the objects have IRAC1 or IRAC2 <= the irac cut\n",
    "- Do the objects have well-defined redshift PDFs in COSMOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST CUT\n",
      "Number of C20 spectra: 37976\n",
      "Number of Grism redshifts: 11856\n"
     ]
    }
   ],
   "source": [
    "## MAKE MAG CUT AND CHECK MASS ##\n",
    "    # Find idx in original C20 cat and cut based on mag\n",
    "    # Check if in COSMOS catalog\n",
    "\n",
    "## GB\n",
    "\n",
    "spec_cids = c20s[:,0].astype(int) - 1   \n",
    "spec_gals = c20p[spec_cids]\n",
    "g_spec = np.where(  ((spec_gals[\"IRAC_CH1_MAG\"] <= IRAC_cut) | (spec_gals[\"IRAC_CH2_MAG\"] <= IRAC_cut))     # IRAC\n",
    "                  & (c20s[:,0] > 0)        # Is in COSMOS\n",
    "                 & (spec_gals['lp_zPDF'] == spec_gals['lp_zPDF'])       # Median is defined\n",
    "                 & (spec_gals['lp_zPDF_l68'] == spec_gals['lp_zPDF_l68'])   # l68 is defined\n",
    "                 & (spec_gals['lp_zPDF_u68'] == spec_gals['lp_zPDF_u68'])  )    # upper 68 is defined\n",
    "\n",
    "c20s = c20s[g_spec]\n",
    "\n",
    "## GRISM\n",
    "\n",
    "griz_cids = griz[:,4].astype(int)  -1\n",
    "griz_gals = c20p[griz_cids]\n",
    "g_griz = np.where(((griz_gals[\"IRAC_CH1_MAG\"] <= IRAC_cut) | (griz_gals[\"IRAC_CH2_MAG\"] <= IRAC_cut))\n",
    "                  & (griz[:,4] > 0)        # Is in COSMOS\n",
    "                 & (griz_gals['lp_zPDF'] == griz_gals['lp_zPDF'])       # Median is defined\n",
    "                 & (griz_gals['lp_zPDF_l68'] == griz_gals['lp_zPDF_l68'])   # l68 is defined\n",
    "                 & (griz_gals['lp_zPDF_u68'] == griz_gals['lp_zPDF_u68']) ) # upper 68 is defined\n",
    "griz = griz[g_griz]\n",
    "\n",
    "print(\"POST CUT\")\n",
    "print(f\"Number of C20 spectra: {c20s.shape[0]}\")\n",
    "print(f\"Number of Grism redshifts: {griz.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><h1 align = center>Finding common objects</h1 ></font>      \n",
    "\n",
    "---> Some objects have an associated ground-based and grism-based redshift. I need to handle these differently for the MC, so I'll separate those out first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Grism Objects = 9267\n",
      "Unique Spec Objects = 35428\n",
      "Common Objects = 2589\n"
     ]
    }
   ],
   "source": [
    "## FIND COMMON OBJECTS ##\n",
    "gids = []       # idx in grism catalog of common object\n",
    "sids = []       # idx in spectrum catalog of common object \n",
    "\n",
    "sim_objs = []   # Keep track of info of the object for MC use --> [C20_ID, zs, qf_s, zg, qf_gz]\n",
    "\n",
    "for g_id, c_id in enumerate(griz[:,4].astype(int)):\n",
    "    if c_id > 0:    # First, make sure it's a cosmos object\n",
    "        t = np.where(c_id == c20s[:,0])[0] # Find which objects in the spec-catalog have the cosmos id\n",
    "\n",
    "        if len(t) != 0: # Object is found in both\n",
    "            for ts in t:\n",
    "                gids.append(g_id)   # Add grism id\n",
    "                sids.append(ts)   # Add spec id\n",
    "                sim_objs.append([c_id, griz[g_id][10], griz[g_id][11], griz[g_id][13], griz[g_id][15]])  # Useful data for later\n",
    "\n",
    "\n",
    "# Create unique catalogs\n",
    "spec_unique = np.delete(c20s, sids, axis=0)     \n",
    "griz_unique = np.delete(griz, gids, axis=0)\n",
    "sim_objs = np.array(sim_objs, dtype=float)\n",
    "\n",
    "print(f\"Unique Grism Objects = {len(griz_unique)}\")\n",
    "print(f\"Unique Spec Objects = {len(spec_unique)}\")\n",
    "print(f\"Common Objects = {len(sim_objs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><h1 align = center>Run MC for Spectra</h1 ></font>      \n",
    "\n",
    "---> So, we now have three classes of spectra to run an MC for. We have unique GB spectra, unique Grism spectra, and ones that have a mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREP STORAGE ARRAY ## \n",
    "niter = 100\n",
    "\n",
    "dtypes = [c20p.dtype.descr[0]] + [(f\"MC_iter{n}\", \">f8\") for n in range(niter)]\n",
    "\n",
    "# Make array to fill\n",
    "spec_mc = np.zeros(shape=(len(spec_unique) + len(griz_unique) + len(sim_objs)), dtype=dtypes)\n",
    "\n",
    "which_z = np.zeros(shape=(len(spec_unique) + len(griz_unique) + len(sim_objs)), dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good spectra:  17934\n"
     ]
    }
   ],
   "source": [
    "### Narrow down the spec-targets ###\n",
    "\n",
    "qfs = spec_unique[:,13] % 10        # Find last digit of qf\n",
    "\n",
    "spec_use_idxs = np.where( (ra_range[0]<= spec_unique[:,4]) & (spec_unique[:,4] <= ra_range[1])          # RA check\n",
    "                 & (dec_range[0] <= spec_unique[:,6]) & (spec_unique[:,6] <= dec_range[1])      # Dec check\n",
    "                 & (  ((qfs >=2.)&(qfs<3.))  |  ((qfs>=9.)&(qfs<10.)) | ((qfs>=3.)&(qfs<5.)))   )[0] # QF check         \n",
    "\n",
    "\n",
    "spec_use = spec_unique[spec_use_idxs]     # Trim the spec catalog to only include galaxies I care about\n",
    "print(\"Good spectra: \", len(spec_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419f86aa849f4d9f8d150962fbc66613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17934 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spectra =  17934\n",
      "Number of converged fits =  17924\n"
     ]
    }
   ],
   "source": [
    "### Create small catalog of spec/ grism fits ###\n",
    "s_fits = []\n",
    "\n",
    "for s_id, s in tqdm(enumerate(spec_use), total=len(spec_use)):\n",
    "    c_id = int(s[0])\n",
    "    \n",
    "    # Check if already been fit\n",
    "    f_ids = np.where(g_fits[:,0].astype(int) == c_id)[0]\n",
    "    if len(f_ids) != 0:    # Already been fit\n",
    "        s_fits.append(g_fits[f_ids[0]])\n",
    "        continue\n",
    "    \n",
    "    # Hasn't been fit\n",
    "    else:\n",
    "        a, w, l, r = fitDist(c20p[\"lp_zPDF\"][c_id-1], c20p[\"lp_zPDF_l68\"][c_id-1], c20p[\"lp_zPDF_u68\"][c_id-1])\n",
    "        #Check to see if fit converged\n",
    "        f_med = skewnorm(a,scale=w,loc=l).median()\n",
    "        if np.abs(f_med - c20p[\"lp_zPDF\"][c_id-1] ) < 0.1:\n",
    "            s_fits.append([c_id, a,w,l,r])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "s_fits = np.array(s_fits)\n",
    "np.save(\"zFits/sFits.npy\", s_fits)\n",
    "\n",
    "print(\"Number of spectra = \", len(spec_use))\n",
    "print(\"Number of converged fits = \", len(s_fits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17924, 32)\n"
     ]
    }
   ],
   "source": [
    "### Pack the fits for use ###\n",
    "s_params = []\n",
    "b_params = []\n",
    "s_fits = np.load(\"zFits/sFits.npy\")\n",
    "for idx, c_id in enumerate(spec_use[:,0]):\n",
    "    idxs = np.where(s_fits[:,0] == c_id)[0]\n",
    "    if len(idxs) != 0:\n",
    "        i = idxs[0]\n",
    "        s_params.append([s_fits[i][1],s_fits[i][2], s_fits[i][3]])\n",
    "    else :\n",
    "        b_params.append(idx)\n",
    "    \n",
    "\n",
    "s_params = np.array(s_params)\n",
    "final_spec = np.delete(spec_use, b_params, axis=0)\n",
    "\n",
    "print(final_spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830c405d383941d4beb26ad21d91d7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### RUN THE MC ####\n",
    "# ========================================================\n",
    "# ========================================================\n",
    "z_range = [2,3]         # Redshift range for \n",
    "\n",
    "\n",
    "spec_z = final_spec[:,11]         # orginal spec-z\n",
    "\n",
    "# Set the MC weights based on the quality flags\n",
    "qfs = final_spec[:,13] % 10      \n",
    "spec_weights = np.select( [(qfs >=2.)&(qfs<3.),(qfs>=9.)&(qfs<10.), (qfs>=3.)&(qfs<5.) ],\n",
    "                [0.7, 0.7, 0.993],\n",
    "                default=0)\n",
    "# ========================================================\n",
    "# ========================================================\n",
    "# ========================================================\n",
    "\n",
    "## MC ##\n",
    "spec_ids, new_szs, drawn_idxs = MCz(niter, spec_z, spec_weights, z_range, my_PDF,\n",
    "                     verbose=True, alpha = s_params[:,0], omega = s_params[:,1], loc = s_params[:,2])\n",
    "\n",
    "## WRITE TO RESULT FILE ##\n",
    "\n",
    "# Update dtypes\n",
    "dtypes = [c20p.dtype.descr[0]] + [(f\"MC_iter{n}\", \">f8\") for n in range(niter)]\n",
    "\n",
    "# Make array to fill\n",
    "write_arr = np.zeros(shape=(len(final_spec)), dtype=dtypes)\n",
    "\n",
    "write_arr[\"ID\"] = final_spec[:,0]\n",
    "for n in range(niter):\n",
    "    write_arr[f\"MC_iter{n}\"] = new_szs[:,n]\n",
    "    new_ids = drawn_idxs[n]\n",
    "\n",
    "    which_z[f\"MC_iter{n}\"][:len(new_szs)] = np.ones(len(new_szs))\n",
    "    which_z[f\"MC_iter{n}\"][:len(new_szs)][new_ids] = np.zeros(len(new_ids))\n",
    "\n",
    "np.save(r\"C:/Users/sikor/OneDrive/Desktop/BigData/COSMOS2020/C20_spec_MC_100.npy\", write_arr)\n",
    "\n",
    "spec_mc[\"ID\"][:len(new_szs)] = final_spec[:,0]     # update with cosmos IDs\n",
    "which_z[f\"ID\"][:len(new_szs)] = final_spec[:,0]\n",
    "\n",
    "\n",
    "for n in range(niter):\n",
    "    spec_mc[f\"MC_iter{n}\"][:len(new_szs)] = new_szs[:,n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Grism spectra:  3768\n"
     ]
    }
   ],
   "source": [
    "### Narrow down the griz-targets ###\n",
    "\n",
    "qfs = griz_unique[:,15]  \n",
    "\n",
    "griz_use_idxs = np.where( (ra_range[0]<= griz_unique[:,1]) & (griz_unique[:,1] <= ra_range[1])          # RA check\n",
    "                 & (dec_range[0] <= griz_unique[:,2]) & (griz_unique[:,2] <= dec_range[1])      # Dec check\n",
    "                 & (  (qfs==3)  |  (qfs==4) | (qfs==5) )        # QF check\n",
    "                 & (griz_unique[:,5]== 0))[0]          # Not a blended object\n",
    "\n",
    "griz_use = griz_unique[griz_use_idxs]     # Trim the spec catalog to only include galaxies I care about\n",
    "print(\"Good Grism spectra: \", len(griz_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8898ca889bf649b68a56d29bb1b88db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3768 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spectra =  3768\n",
      "Number of converged fits =  3767\n"
     ]
    }
   ],
   "source": [
    "### Create small catalog of spec/ grism fits ###\n",
    "griz_fits = []\n",
    "\n",
    "for g_id, g in tqdm(enumerate(griz_use), total=len(griz_use)):\n",
    "    g_id = int(g[4])\n",
    "    \n",
    "    # Check if already been fit\n",
    "    f_ids = np.where(g_fits[:,0].astype(int) == g_id)[0]\n",
    "    if len(f_ids) != 0:    # Already been fit\n",
    "        griz_fits.append(g_fits[f_ids[0]])\n",
    "        continue\n",
    "    \n",
    "    # Hasn't been fit\n",
    "    else:\n",
    "        a, w, l, r = fitDist(c20p[\"lp_zPDF\"][g_id-1], c20p[\"lp_zPDF_l68\"][g_id-1], c20p[\"lp_zPDF_u68\"][g_id-1])\n",
    "        #Check to see if fit converged\n",
    "        f_med = skewnorm(a,scale=w,loc=l).median()\n",
    "        if np.abs(f_med - c20p[\"lp_zPDF\"][g_id-1] ) < 0.1:\n",
    "            griz_fits.append([g_id, a,w,l,r])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "griz_fits = np.array(griz_fits)\n",
    "np.save(\"zFits/gFits.npy\", griz_fits)\n",
    "\n",
    "print(\"Number of spectra = \", len(griz_use))\n",
    "print(\"Number of converged fits = \", len(griz_fits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3767, 16)\n"
     ]
    }
   ],
   "source": [
    "### Pack the fits for use ###\n",
    "g_params = []\n",
    "b_params = []\n",
    "griz_fits = np.load(\"zFits/gFits.npy\")\n",
    "\n",
    "for idx, c_id in enumerate(griz_use[:,4]):\n",
    "    idxs = np.where(griz_fits[:,0] == c_id)[0]\n",
    "    if len(idxs) != 0:\n",
    "        i = idxs[0]\n",
    "        g_params.append([griz_fits[i][1],griz_fits[i][2], griz_fits[i][3]])\n",
    "    else :\n",
    "        b_params.append(idx)\n",
    "    \n",
    "\n",
    "g_params = np.array(g_params)\n",
    "final_griz = np.delete(griz_use, b_params, axis=0)\n",
    "print(final_griz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce83d9cd5b56491693a62950a74bc5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### RUN THE MC ####\n",
    "# ========================================================\n",
    "# ========================================================\n",
    "z_range = [2,3]         # Redshift range for \n",
    "\n",
    "\n",
    "griz_z = final_griz[:,13].astype(float)         # orginal spec-z\n",
    "griz_width = 46/14100*(1+griz_z)       # Width of the normal distribution to draw from\n",
    "\n",
    "\n",
    "\n",
    "# Set the MC weights based on the quality flags\n",
    "qfs = final_griz[:,-1]  \n",
    "griz_weights = np.select( [qfs==5, qfs==4, qfs==3 ],\n",
    "                [0.925, 0.818, 0.668],\n",
    "                default=0)\n",
    "\n",
    "# ========================================================\n",
    "# ========================================================\n",
    "# ========================================================\n",
    "spec_mc[\"ID\"][len(new_szs):len(new_szs) + len(final_griz)] = final_griz[:,4]     # update with cosmos IDs\n",
    "which_z[\"ID\"][len(new_szs):len(new_szs) + len(final_griz)] = final_griz[:,4]\n",
    "\n",
    "for n in tqdm(range(niter)):\n",
    "\n",
    "    gzs = np.random.normal(griz_z, griz_width)\n",
    "\n",
    "    ## MC ##\n",
    "    griz_ids, new_g, new_ids = MCz(1, gzs, griz_weights, z_range, my_PDF, \n",
    "                        verbose=False, alpha = griz_fits[:,1], omega = griz_fits[:,2], loc = griz_fits[:,3])\n",
    "    \n",
    "    new_gzs = new_g.flatten()\n",
    "    \n",
    "    spec_mc[f\"MC_iter{n}\"][len(new_szs):len(new_szs) + len(final_griz)] = new_gzs\n",
    "    \n",
    "    which_z[f\"MC_iter{n}\"][len(new_szs):len(new_szs) + len(final_griz)] = 2*np.ones(len(new_ids))\n",
    "    which_z[f\"MC_iter{n}\"][len(new_szs):len(new_szs) + len(final_griz)][new_ids] = np.zeros(len(new_ids))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# WRITE TO RESULT FILE ##\n",
    "\n",
    "# # Update dtypes\n",
    "# dtypes = [c20p.dtype.descr[0]] + [(f\"MC_iter{n}\", \">f8\") for n in range(niter)]\n",
    "\n",
    "# # Make array to fill\n",
    "# write_arr = np.zeros(shape=(len(griz)), dtype=dtypes)\n",
    "\n",
    "# write_arr[\"ID\"] = griz[:,0]\n",
    "# for n in range(niter):\n",
    "#     write_arr[f\"MC_iter{n}\"] = new_gzs[:,n]\n",
    "\n",
    "# np.save(r\"C:/Users/sikor/OneDrive/Desktop/BigData/COSMOS2020/grizli_MC_1000.npy\", write_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f168112e894511bcc829f0e404cf93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spectra =  2589\n",
      "Number of converged fits =  2584\n"
     ]
    }
   ],
   "source": [
    "## Pack parameters of spectra from cosmos catalog ##\n",
    "bad_com = [] # where parameters have a nan\n",
    "com_fits = []\n",
    "for idx, c_id in tqdm(enumerate(sim_objs[:,0].astype(int)), total=len(sim_objs[:,0]), ):\n",
    "\n",
    "    ra, dec = c20p[\"ALPHA_J2000\"][c_id-1], c20p[\"DELTA_J2000\"][c_id-1]\n",
    "    if (ra >= ra_range[1]) or (ra <= ra_range[0]) or (dec >= dec_range[1]) or (dec<= dec_range[0]):\n",
    "        continue\n",
    "\n",
    "    if c_id == -99:\n",
    "        continue\n",
    "    \n",
    "    # Check if already been fit\n",
    "    f_ids = np.where(g_fits[:,0].astype(int) == c_id)[0]\n",
    "    if len(f_ids) != 0:    # Already been fit\n",
    "        com_fits.append(g_fits[f_ids[0]])\n",
    "        continue\n",
    "    \n",
    "    # Hasn't been fit\n",
    "    else:\n",
    "        a, w, l, r = fitDist(c20p[\"lp_zPDF\"][c_id-1], c20p[\"lp_zPDF_l68\"][c_id-1], c20p[\"lp_zPDF_u68\"][c_id-1])\n",
    "        #Check to see if fit converged\n",
    "        f_med = skewnorm(a,scale=w,loc=l).median()\n",
    "        if np.abs(f_med - c20p[\"lp_zPDF\"][c_id-1] ) < 0.1:\n",
    "            com_fits.append([c_id, a,w,l,r])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "com_fits = np.array(com_fits)\n",
    "bad_com = np.array(bad_com)\n",
    "np.save(\"zFits/cFits.npy\", com_fits)\n",
    "\n",
    "print(\"Number of spectra = \", len(sim_objs))\n",
    "print(\"Number of converged fits = \", len(com_fits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2584, 5)\n"
     ]
    }
   ],
   "source": [
    "### Pack the fits for use ###\n",
    "g_params = []\n",
    "b_params = []\n",
    "com_fits = np.load(\"zFits/cFits.npy\")\n",
    "\n",
    "\n",
    "for idx, c_id in enumerate(sim_objs[:,0].astype(float).astype(int)):\n",
    "    idxs = np.where(com_fits[:,0] == c_id)[0]\n",
    "    if len(idxs) != 0:\n",
    "        i = idxs[0]\n",
    "        g_params.append([com_fits[i][1],com_fits[i][2], com_fits[i][3]])\n",
    "    else :\n",
    "        b_params.append(idx)\n",
    "    \n",
    "\n",
    "g_params = np.array(g_params)\n",
    "final_c = np.delete(sim_objs, b_params, axis=0)\n",
    "print(final_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda87681efac42febf6158831216973d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### RUN THE MC ####\n",
    "# ========================================================\n",
    "# ========================================================\n",
    "z_range = [2,3]         # Redshift range for \n",
    "\n",
    "\n",
    "## Weights\n",
    "\n",
    "# Spectra weights\n",
    "qfs = final_c[:,2] % 10      # \n",
    "spec_weights = np.select( [(qfs >=2.)&(qfs<3.),(qfs>=9.)&(qfs<10.), (qfs>=3.)&(qfs<5.) ],\n",
    "                [0.7, 0.7, 0.993],\n",
    "                default=0)\n",
    "\n",
    "# Grizli weights \n",
    "qfg = final_c[:,-1]  \n",
    "griz_weights = np.select( [qfg==5, qfg==4, qfg==3 ],\n",
    "                [0.925, 0.818, 0.668],\n",
    "                default=0)\n",
    "\n",
    "# Combine\n",
    "sim_weights = np.c_[spec_weights, griz_weights]\n",
    "\n",
    "# Keep track of which flag is higher\n",
    "max_id = np.argmax(sim_weights, axis=1)\n",
    "\n",
    "# Sort the weights\n",
    "sim_weights = np.sort(sim_weights, axis=1)\n",
    "\n",
    "\n",
    "spec_mc[\"ID\"][len(new_szs) + len(final_griz):len(new_szs) + len(final_griz) + len(final_c)] = final_c[:,0]     # update with cosmos IDs\n",
    "\n",
    "which_z[\"ID\"][len(new_szs) + len(final_griz):len(new_szs) + len(final_griz) + len(final_c)] = final_c[:,0]     # update with cosmos IDs\n",
    "\n",
    "# ========================================================\n",
    "# ========================================================\n",
    "# ========================================================\n",
    "\n",
    "for n in tqdm(range(niter)):\n",
    "\n",
    "    # Draw random number for each object:\n",
    "    mc_rns = np.random.random(size=len(sim_weights))\n",
    "\n",
    "    # Choose specz, griz, or photoz\n",
    "    z_choice = []   \n",
    "    for rn_idx, rn in enumerate(mc_rns):\n",
    "        sw = sim_weights[rn_idx]    # weights for this spectrum\n",
    "\n",
    "        if rn < sw[1]: \n",
    "            z_choice.append(max_id[rn_idx]) # Choose better spectrum\n",
    "\n",
    "        elif (rn >=sw[1]) and (rn < sw[1]+sw[0]*(1-sw[1])):\n",
    "            z_choice.append(int(not(max_id[rn_idx])))    # Choose worse spectrum\n",
    "\n",
    "        else:\n",
    "            z_choice.append(2)  # Choose photoz\n",
    "\n",
    "    z_choice = np.array(z_choice)\n",
    "    \n",
    "    # Make random grism redshifts\n",
    "    g_rand = np.random.normal(final_c[:,3], 46/14100*(1+final_c[:,3]) )\n",
    "\n",
    "    # Pick which redshift to use\n",
    "    z_meds = np.select([z_choice == 0, z_choice == 1, z_choice == 2], \n",
    "                       [final_c[:,1],  g_rand, 2])\n",
    "    \n",
    "    # For \"which_z\" storage only\n",
    "    wz = np.select([z_choice==0, z_choice==1, z_choice==2],\n",
    "                   [1, 2, 0])\n",
    "    \n",
    "    # Assign weights\n",
    "    ws = [0 if zi == 2 else 1 for zi in z_choice]\n",
    "\n",
    "\n",
    "    ## MC ##\n",
    "    _, new_sim , _ = MCz(1, z_meds, ws, z_range, my_PDF,\n",
    "                       verbose=False, alpha = g_params[:,0], omega = g_params[:,1], loc = g_params[:,2])\n",
    "    \n",
    "    new_simz = new_sim.flatten()\n",
    "    # new_simz[bad_com] = -99\n",
    "    \n",
    "    spec_mc[f\"MC_iter{n}\"][len(new_szs) + len(final_griz):len(new_szs) + len(final_griz) + len(final_c)] = new_simz\n",
    "    which_z[f\"MC_iter{n}\"][len(new_szs) + len(final_griz):len(new_szs) + len(final_griz) + len(final_c)] = wz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_mc = spec_mc[:len(new_szs) + len(final_griz) + len(final_c)]\n",
    "which_z = which_z[:len(new_szs) + len(final_griz) + len(final_c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r\"C:/Users/sikor/OneDrive/Desktop/BigData/COSMOS2020/MC_spec.npy\", spec_mc)\n",
    "np.save(r\"C:/Users/sikor/OneDrive/Desktop/BigData/COSMOS2020/MC_which.npy\", which_z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
